{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: llm2vec in ./clinicenv/lib/python3.12/site-packages (0.2.2)\n",
      "Requirement already satisfied: numpy in ./clinicenv/lib/python3.12/site-packages (from llm2vec) (2.1.3)\n",
      "Requirement already satisfied: tqdm in ./clinicenv/lib/python3.12/site-packages (from llm2vec) (4.66.6)\n",
      "Requirement already satisfied: torch in ./clinicenv/lib/python3.12/site-packages (from llm2vec) (2.5.1)\n",
      "Requirement already satisfied: peft in ./clinicenv/lib/python3.12/site-packages (from llm2vec) (0.13.2)\n",
      "Collecting transformers<=4.40.2,>=4.39.1 (from llm2vec)\n",
      "  Using cached transformers-4.40.2-py3-none-any.whl.metadata (137 kB)\n",
      "Requirement already satisfied: datasets in ./clinicenv/lib/python3.12/site-packages (from llm2vec) (3.1.0)\n",
      "Requirement already satisfied: evaluate in ./clinicenv/lib/python3.12/site-packages (from llm2vec) (0.4.3)\n",
      "Requirement already satisfied: scikit-learn in ./clinicenv/lib/python3.12/site-packages (from llm2vec) (1.5.2)\n",
      "Requirement already satisfied: filelock in ./clinicenv/lib/python3.12/site-packages (from transformers<=4.40.2,>=4.39.1->llm2vec) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in ./clinicenv/lib/python3.12/site-packages (from transformers<=4.40.2,>=4.39.1->llm2vec) (0.26.2)\n",
      "Requirement already satisfied: packaging>=20.0 in ./clinicenv/lib/python3.12/site-packages (from transformers<=4.40.2,>=4.39.1->llm2vec) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./clinicenv/lib/python3.12/site-packages (from transformers<=4.40.2,>=4.39.1->llm2vec) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./clinicenv/lib/python3.12/site-packages (from transformers<=4.40.2,>=4.39.1->llm2vec) (2024.9.11)\n",
      "Requirement already satisfied: requests in ./clinicenv/lib/python3.12/site-packages (from transformers<=4.40.2,>=4.39.1->llm2vec) (2.32.3)\n",
      "Collecting tokenizers<0.20,>=0.19 (from transformers<=4.40.2,>=4.39.1->llm2vec)\n",
      "  Using cached tokenizers-0.19.1-cp312-cp312-macosx_11_0_arm64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in ./clinicenv/lib/python3.12/site-packages (from transformers<=4.40.2,>=4.39.1->llm2vec) (0.4.5)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in ./clinicenv/lib/python3.12/site-packages (from datasets->llm2vec) (18.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in ./clinicenv/lib/python3.12/site-packages (from datasets->llm2vec) (0.3.8)\n",
      "Requirement already satisfied: pandas in ./clinicenv/lib/python3.12/site-packages (from datasets->llm2vec) (2.2.3)\n",
      "Requirement already satisfied: xxhash in ./clinicenv/lib/python3.12/site-packages (from datasets->llm2vec) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in ./clinicenv/lib/python3.12/site-packages (from datasets->llm2vec) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in ./clinicenv/lib/python3.12/site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets->llm2vec) (2024.9.0)\n",
      "Requirement already satisfied: aiohttp in ./clinicenv/lib/python3.12/site-packages (from datasets->llm2vec) (3.10.10)\n",
      "Requirement already satisfied: psutil in ./clinicenv/lib/python3.12/site-packages (from peft->llm2vec) (6.1.0)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in ./clinicenv/lib/python3.12/site-packages (from peft->llm2vec) (1.1.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in ./clinicenv/lib/python3.12/site-packages (from torch->llm2vec) (4.12.2)\n",
      "Requirement already satisfied: networkx in ./clinicenv/lib/python3.12/site-packages (from torch->llm2vec) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in ./clinicenv/lib/python3.12/site-packages (from torch->llm2vec) (3.1.4)\n",
      "Requirement already satisfied: setuptools in ./clinicenv/lib/python3.12/site-packages (from torch->llm2vec) (75.3.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in ./clinicenv/lib/python3.12/site-packages (from torch->llm2vec) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./clinicenv/lib/python3.12/site-packages (from sympy==1.13.1->torch->llm2vec) (1.3.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in ./clinicenv/lib/python3.12/site-packages (from scikit-learn->llm2vec) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./clinicenv/lib/python3.12/site-packages (from scikit-learn->llm2vec) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./clinicenv/lib/python3.12/site-packages (from scikit-learn->llm2vec) (3.5.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in ./clinicenv/lib/python3.12/site-packages (from aiohttp->datasets->llm2vec) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./clinicenv/lib/python3.12/site-packages (from aiohttp->datasets->llm2vec) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./clinicenv/lib/python3.12/site-packages (from aiohttp->datasets->llm2vec) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./clinicenv/lib/python3.12/site-packages (from aiohttp->datasets->llm2vec) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./clinicenv/lib/python3.12/site-packages (from aiohttp->datasets->llm2vec) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in ./clinicenv/lib/python3.12/site-packages (from aiohttp->datasets->llm2vec) (1.17.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./clinicenv/lib/python3.12/site-packages (from requests->transformers<=4.40.2,>=4.39.1->llm2vec) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./clinicenv/lib/python3.12/site-packages (from requests->transformers<=4.40.2,>=4.39.1->llm2vec) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./clinicenv/lib/python3.12/site-packages (from requests->transformers<=4.40.2,>=4.39.1->llm2vec) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./clinicenv/lib/python3.12/site-packages (from requests->transformers<=4.40.2,>=4.39.1->llm2vec) (2024.8.30)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./clinicenv/lib/python3.12/site-packages (from jinja2->torch->llm2vec) (3.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./clinicenv/lib/python3.12/site-packages (from pandas->datasets->llm2vec) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./clinicenv/lib/python3.12/site-packages (from pandas->datasets->llm2vec) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./clinicenv/lib/python3.12/site-packages (from pandas->datasets->llm2vec) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in ./clinicenv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets->llm2vec) (1.16.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./clinicenv/lib/python3.12/site-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets->llm2vec) (0.2.0)\n",
      "Using cached transformers-4.40.2-py3-none-any.whl (9.0 MB)\n",
      "Using cached tokenizers-0.19.1-cp312-cp312-macosx_11_0_arm64.whl (2.4 MB)\n",
      "Installing collected packages: tokenizers, transformers\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.20.3\n",
      "    Uninstalling tokenizers-0.20.3:\n",
      "      Successfully uninstalled tokenizers-0.20.3\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.46.2\n",
      "    Uninstalling transformers-4.46.2:\n",
      "      Successfully uninstalled transformers-4.46.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "sentence-transformers 3.2.1 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.40.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed tokenizers-0.19.1 transformers-4.40.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Collecting flash-attn\n",
      "  Using cached flash_attn-2.6.3.tar.gz (2.6 MB)\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mPreparing metadata \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mpyproject.toml\u001b[0m\u001b[1;32m)\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[32 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m fatal: not a git repository (or any of the parent directories): .git\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m torch.__version__  = 2.5.1\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m <string>:95: UserWarning: flash_attn was requested, but nvcc was not found.  Are you sure your environment has nvcc available?  If you're installing within a container from https://hub.docker.com/r/pytorch/pytorch, only images whose names contain 'devel' will provide nvcc.\n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \"/Users/mehakgarg/Downloads/CMC/Senior/Clinic/clinicenv/lib/python3.12/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\", line 353, in <module>\n",
      "  \u001b[31m   \u001b[0m     main()\n",
      "  \u001b[31m   \u001b[0m   File \"/Users/mehakgarg/Downloads/CMC/Senior/Clinic/clinicenv/lib/python3.12/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\", line 335, in main\n",
      "  \u001b[31m   \u001b[0m     json_out['return_val'] = hook(**hook_input['kwargs'])\n",
      "  \u001b[31m   \u001b[0m                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m   File \"/Users/mehakgarg/Downloads/CMC/Senior/Clinic/clinicenv/lib/python3.12/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\", line 149, in prepare_metadata_for_build_wheel\n",
      "  \u001b[31m   \u001b[0m     return hook(metadata_directory, config_settings)\n",
      "  \u001b[31m   \u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m   File \"/Users/mehakgarg/Downloads/CMC/Senior/Clinic/clinicenv/lib/python3.12/site-packages/setuptools/build_meta.py\", line 376, in prepare_metadata_for_build_wheel\n",
      "  \u001b[31m   \u001b[0m     self.run_setup()\n",
      "  \u001b[31m   \u001b[0m   File \"/Users/mehakgarg/Downloads/CMC/Senior/Clinic/clinicenv/lib/python3.12/site-packages/setuptools/build_meta.py\", line 521, in run_setup\n",
      "  \u001b[31m   \u001b[0m     super().run_setup(setup_script=setup_script)\n",
      "  \u001b[31m   \u001b[0m   File \"/Users/mehakgarg/Downloads/CMC/Senior/Clinic/clinicenv/lib/python3.12/site-packages/setuptools/build_meta.py\", line 319, in run_setup\n",
      "  \u001b[31m   \u001b[0m     exec(code, locals())\n",
      "  \u001b[31m   \u001b[0m   File \"<string>\", line 179, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"/Users/mehakgarg/Downloads/CMC/Senior/Clinic/clinicenv/lib/python3.12/site-packages/torch/utils/cpp_extension.py\", line 1078, in CUDAExtension\n",
      "  \u001b[31m   \u001b[0m     library_dirs += library_paths(cuda=True)\n",
      "  \u001b[31m   \u001b[0m                     ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m   File \"/Users/mehakgarg/Downloads/CMC/Senior/Clinic/clinicenv/lib/python3.12/site-packages/torch/utils/cpp_extension.py\", line 1209, in library_paths\n",
      "  \u001b[31m   \u001b[0m     if (not os.path.exists(_join_cuda_home(lib_dir)) and\n",
      "  \u001b[31m   \u001b[0m                            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m   File \"/Users/mehakgarg/Downloads/CMC/Senior/Clinic/clinicenv/lib/python3.12/site-packages/torch/utils/cpp_extension.py\", line 2416, in _join_cuda_home\n",
      "  \u001b[31m   \u001b[0m     raise OSError('CUDA_HOME environment variable is not set. '\n",
      "  \u001b[31m   \u001b[0m OSError: CUDA_HOME environment variable is not set. Please set it to your CUDA install root.\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[?25h\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
      "\u001b[31m╰─>\u001b[0m See above for output.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
      "\u001b[1;36mhint\u001b[0m: See above for details.\n",
      "Requirement already satisfied: huggingface in ./clinicenv/lib/python3.12/site-packages (0.0.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: sentence-transformers in ./clinicenv/lib/python3.12/site-packages (3.2.1)\n",
      "Collecting transformers<5.0.0,>=4.41.0 (from sentence-transformers)\n",
      "  Using cached transformers-4.46.2-py3-none-any.whl.metadata (44 kB)\n",
      "Requirement already satisfied: tqdm in ./clinicenv/lib/python3.12/site-packages (from sentence-transformers) (4.66.6)\n",
      "Requirement already satisfied: torch>=1.11.0 in ./clinicenv/lib/python3.12/site-packages (from sentence-transformers) (2.5.1)\n",
      "Requirement already satisfied: scikit-learn in ./clinicenv/lib/python3.12/site-packages (from sentence-transformers) (1.5.2)\n",
      "Requirement already satisfied: scipy in ./clinicenv/lib/python3.12/site-packages (from sentence-transformers) (1.14.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in ./clinicenv/lib/python3.12/site-packages (from sentence-transformers) (0.26.2)\n",
      "Requirement already satisfied: Pillow in ./clinicenv/lib/python3.12/site-packages (from sentence-transformers) (11.0.0)\n",
      "Requirement already satisfied: filelock in ./clinicenv/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./clinicenv/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.9.0)\n",
      "Requirement already satisfied: packaging>=20.9 in ./clinicenv/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./clinicenv/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: requests in ./clinicenv/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./clinicenv/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.12.2)\n",
      "Requirement already satisfied: networkx in ./clinicenv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in ./clinicenv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
      "Requirement already satisfied: setuptools in ./clinicenv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (75.3.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in ./clinicenv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./clinicenv/lib/python3.12/site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: numpy>=1.17 in ./clinicenv/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.1.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./clinicenv/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.9.11)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in ./clinicenv/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.4.5)\n",
      "Collecting tokenizers<0.21,>=0.20 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Using cached tokenizers-0.20.3-cp312-cp312-macosx_11_0_arm64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./clinicenv/lib/python3.12/site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./clinicenv/lib/python3.12/site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./clinicenv/lib/python3.12/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./clinicenv/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./clinicenv/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./clinicenv/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./clinicenv/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2024.8.30)\n",
      "Using cached transformers-4.46.2-py3-none-any.whl (10.0 MB)\n",
      "Using cached tokenizers-0.20.3-cp312-cp312-macosx_11_0_arm64.whl (2.6 MB)\n",
      "Installing collected packages: tokenizers, transformers\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.19.1\n",
      "    Uninstalling tokenizers-0.19.1:\n",
      "      Successfully uninstalled tokenizers-0.19.1\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.40.2\n",
      "    Uninstalling transformers-4.40.2:\n",
      "      Successfully uninstalled transformers-4.40.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "llm2vec 0.2.2 requires transformers<=4.40.2,>=4.39.1, but you have transformers 4.46.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed tokenizers-0.20.3 transformers-4.46.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install llm2vec\n",
    "!pip install flash-attn --no-build-isolation\n",
    "!pip install huggingface\n",
    "!pip install sentence-transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mehakgarg/Downloads/CMC/Senior/Clinic/clinicenv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from llm2vec import LLM2Vec\n",
    "from huggingface_hub import login\n",
    "from transformers import AutoTokenizer, AutoModel, AutoConfig\n",
    "from peft import PeftModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "login(token=\"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\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Potential model paths \n",
    "\n",
    "1. McGill-NLP/LLM2Vec-Mistral-7B-Instruct-v2-mnt\n",
    "2. McGill-NLP/LLM2Vec-Meta-Llama-3-8B-Instruct-mntp \n",
    "\n",
    "(Specify unsupervised or supervised at the end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"McGill-NLP/LLM2Vec-Meta-Llama-3-8B-Instruct-mntp\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt_tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"McGill-NLP/LLM2Vec-Mistral-7B-Instruct-v2-mntp\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = AutoConfig.from_pretrained(\n",
    "    \"McGill-NLP/LLM2Vec-Mistral-7B-Instruct-v2-mntp\", trust_remote_code=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading shards: 100%|██████████| 3/3 [00:00<00:00,  8.66it/s]\n",
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:00<00:00,  9.58it/s]\n",
      "Some weights of the model checkpoint at mistralai/Mistral-7B-Instruct-v0.2 were not used when initializing MistralEncoderModel: ['lm_head.weight']\n",
      "- This IS expected if you are initializing MistralEncoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing MistralEncoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = AutoModel.from_pretrained(\n",
    "    \"McGill-NLP/LLM2Vec-Mistral-7B-Instruct-v2-mntp\",\n",
    "    trust_remote_code=True,\n",
    "    config=config,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PeftModel.from_pretrained(\n",
    "    model,\n",
    "    \"McGill-NLP/LLM2Vec-Meta-Llama-3-8B-Instruct-mntp\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2v = LLM2Vec(model, tokenizer, pooling_mode=\"mean\", max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction = (\n",
    "    \"Given a web search query, retrieve relevant passages that answer the query:\"\n",
    ")\n",
    "queries = [\n",
    "    [instruction, \"how much protein should a female eat\"],\n",
    "    [instruction, \"summit define\"],\n",
    "]\n",
    "q_reps = l2v.encode(queries)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [\n",
    "    \"As a general guideline, the CDC's average requirement of protein for women ages 19 to 70 is 46 grams per day. But, as you can see from this chart, you'll need to increase that if you're expecting or training for a marathon. Check out the chart below to see how much protein you should be eating each day.\",\n",
    "    \"Definition of summit for English Language Learners. : 1  the highest point of a mountain : the top of a mountain. : 2  the highest level. : 3  a meeting or series of meetings between the leaders of two or more governments.\",\n",
    "]\n",
    "d_reps = l2v.encode(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_reps_norm = torch.nn.functional.normalize(q_reps, p=2, dim=1)\n",
    "d_reps_norm = torch.nn.functional.normalize(d_reps, p=2, dim=1)\n",
    "cos_sim = torch.mm(q_reps_norm, d_reps_norm.transpose(0, 1))\n",
    "\n",
    "print(cos_sim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering.py Reproduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sklearn\n",
    "import sklearn.cluster\n",
    "import sklearn.metrics.cluster\n",
    "import tqdm\n",
    "import datasets\n",
    "\n",
    "\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.metrics.cluster import v_measure_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"./data/customer_support_tickets.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(dataset)\n",
    "df_sample = df.sample(n=100, random_state=42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = df_sample['Ticket Description'].tolist()\n",
    "labels = df_sample['Ticket Type'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction = \"Identify the main issue or topic of this customer support ticket: \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading shards: 100%|██████████| 3/3 [00:00<00:00,  9.38it/s]\n",
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:00<00:00,  5.71it/s]\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading model...\")\n",
    "\n",
    "model = LLM2Vec.from_pretrained(\n",
    "    \"McGill-NLP/LLM2Vec-Mistral-7B-Instruct-v2-mntp\",\n",
    "    peft_model_name_or_path=\"McGill-NLP/LLM2Vec-Mistral-7B-Instruct-v2-mntp-supervised\",\n",
    "    device_map=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_instruction(instruction, sentences):\n",
    "    return [[instruction, s, 0] for s in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "clustering_batch_size = 32  # Reduced for smaller dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding 100 sentences...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 4/4 [56:33<00:00, 848.29s/it] \n"
     ]
    }
   ],
   "source": [
    "print(f\"Encoding {len(sentences)} sentences...\")\n",
    "new_sentences = append_instruction(instruction, sentences)\n",
    "corpus_embeddings = np.asarray(model.encode(new_sentences, batch_size=batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting Mini-Batch K-Means model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "print(\"Fitting Mini-Batch K-Means model...\")\n",
    "n_clusters = min(len(set(labels)), 10)  # cap at 10 clusters for this small sample\n",
    "clustering_model = sklearn.cluster.MiniBatchKMeans(\n",
    "    n_clusters=n_clusters, batch_size=clustering_batch_size\n",
    ")\n",
    "clustering_model.fit(corpus_embeddings)\n",
    "cluster_assignment = clustering_model.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n",
      "V-measure: 0.06312882975604346\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluating...\")\n",
    "v_measure = sklearn.metrics.cluster.v_measure_score(labels, cluster_assignment)\n",
    "print(f\"V-measure: {v_measure}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample['Assigned Cluster'] = cluster_assignment\n",
    "df_sample.to_csv('clustered_support_tickets_sample.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Description: I'm having an issue with the {product_purchased}. Please assist. I'm using xda-developer for something different. If there are issues with the {product_purchased} it's likely you are not using the I've tried clearing the cache and data for the {product_purchased} app, but the issue persists....\n",
      "Ticket Type: Refund request\n",
      "Assigned Cluster: 0\n",
      "Ticket Subject: Product setup\n",
      "Ticket Priority: High\n",
      "\n",
      "Description: I'm having trouble connecting my {product_purchased} to my home Wi-Fi network. It doesn't detect any networks, although other devices are connecting fine. What can be done to resolve this issue? I will refer to this issue I've checked for any available software updates for my {product_purchased}, but there are none....\n",
      "Ticket Type: Product inquiry\n",
      "Assigned Cluster: 4\n",
      "Ticket Subject: Battery life\n",
      "Ticket Priority: Low\n",
      "\n",
      "Description: I'm having an issue with the {product_purchased}. Please assist.\n",
      "\n",
      "Please give credit to: @joeyclay I'm concerned about the security of my {product_purchased} and would like to ensure that my data is safe....\n",
      "Ticket Type: Billing inquiry\n",
      "Assigned Cluster: 1\n",
      "Ticket Subject: Refund request\n",
      "Ticket Priority: Low\n",
      "\n",
      "Description: I'm having an issue with the {product_purchased}. Please assist.\n",
      "\n",
      "4. Check and compare product pricing\n",
      "\n",
      "You will see that prices are based on the current prices on your credit card. If you are a resident of I've noticed a peculiar error message popping up on my {product_purchased} screen. It says '{error_message}'. What does it mean?...\n",
      "Ticket Type: Billing inquiry\n",
      "Assigned Cluster: 2\n",
      "Ticket Subject: Peripheral compatibility\n",
      "Ticket Priority: High\n",
      "\n",
      "Description: I'm having an issue with the {product_purchased}. Please assist.\n",
      "\n",
      "I would like my price to rise so that I can return it.\n",
      "\n",
      "Please notify me if you do not want their refund.\n",
      "\n",
      "Please do I've noticed a sudden decrease in battery life on my {product_purchased}. It used to last much longer....\n",
      "Ticket Type: Refund request\n",
      "Assigned Cluster: 2\n",
      "Ticket Subject: Peripheral compatibility\n",
      "Ticket Priority: Medium\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for i in range(min(5, len(df_sample))):\n",
    "    print(f\"Description: {df_sample['Ticket Description'].iloc[i][:500]}...\") \n",
    "    print(f\"Ticket Type: {df_sample['Ticket Type'].iloc[i]}\")\n",
    "    print(f\"Assigned Cluster: {df_sample['Assigned Cluster'].iloc[i]}\")\n",
    "    print(f\"Ticket Subject: {df_sample['Ticket Subject'].iloc[i]}\")\n",
    "    print(f\"Ticket Priority: {df_sample['Ticket Priority'].iloc[i]}\")\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clinicenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
